* 캐시
    -> cpu 칩 안에 있는 조그마한 메모리
    -> 램과 다르게 연산을 수행 부분과 붙어 있어 읽기 / 쓰기 매우 빠름

    -> cpu 접근 순서
        1. 가장 많이 접근 하는 부분 L1 (4사이클)
        2. 자주 접근하는 부분 L2 (12) 
        3. 접근 부분 L3 (36)

    -> cpu에서 캐시가 작동하는 방식
        1. 메모리를 읽으면 일단 캐시에 저장
        2. 캐시가 가득 찼다면 특정한 방식에 따라 처리
            -> 특정한 방식 = 가장 이전에 쓴(LRU) 캐시를 날려버리고 새로운 캐시 기록

# 파이프라이닝
    -> 한 작업이 다 끝 나기 전에 다음 작업을 시작하는 방식으로 동시에 여러 개의 작업을 동시에 실행

    -> cpu 명렁어 실행 단계
    1. fetch - 읽기
    2. decode - 명령어 해석
    3. execute - 해석된 명령어 실행
    4. write - 마지막 결과

    컴파일러만 재배치?
    ->
    // 현재 a = 0, b = 0;
    a = 1;  // 캐시에 없음
    b = 1;  // 캐시에 있음

    -> a=1; 보다 b=1; 이 더 먼저 실행될 수 있다.

* 수정 순서 (modification order)
    1. 수정 순서란 - 만약에 어떤 객체의 값을 실시간으로 확인할 수 있는 전지전능한 무언가가 있다고 하였을 때, 해당 객체의 값의 변화를 기록
    
    -> 읽는 순서가 동일하다는 것
    5 8 6 3
    ------> a = 8
    -> a가 8을 읽었다면 그 다음에 읽어지는 값은 8, 6, 3 일것이다. 순서 반대로 5를 읽는 일은 없다
    -> 모든 쓰레드들이 동일한 값을 관찰할 필요는 없다.
        -> 쓰레드 1에서 5, 쓰레드 2에서 8 -> 결과만 같다면 괜찮다.

    -> 각 코어가 각각 자신들의 L1, L2 캐시들을 갖고 있다 -> 쓰레드 1에서 a=5 캐시기록 후 코어에 알리지 않으면 -> 쓰레드 a 값 확인할 때 5를 얻는다는 보장이 없음
        -> 매번 기록할 때 마다 캐시에 동기화할 수 있지만 이는 시간을 잡아먹음

* 원자성 (atomicity)
    -> 모든 쓰레드들이 수정 순서에 동의해야하는 이유 -> 모든 연산들이 원자적 일 때
    -> 원자적인 연산이 아닌 경우 모든 쓰레드에서 같은 수정 순서를 관찰할 수 있음이 보장 X -> 프로그램이 정의되지 않은 내용(undefined behavior)

    -> cpu 명령어 1개로 처리하는 명령으로, 중간에 다른 쓰레드가 끼어들 여지가 전혀 없는 연산
        -> 즉, 이 연산을 반 정도 했다는 있을 수 없고 이 연산을 했다 혹은 안 했다만 존재
            -> 마치 원자처럼 쪼갤 수 없다 - 원자적


    ex1) 타입들에 원자적인 연산을 쉽게 할 수 있도록 여러가지 도구들을 지원
        -> 원자적 연산들은 올바른 연산을 위해 굳이 뮤텍스 사용 X
    #include <atomic>
    #include <iostream>
    #include <thread>
    #include <vector>

    void worker(std::atomic<int>& counter) {
    for (int i = 0; i < 10000; i++) {
        counter++;
    }
    }

    int main() {
    std::atomic<int> counter(0);

    std::vector<std::thread> workers;
    for (int i = 0; i < 4; i++) {
        workers.push_back(std::thread(worker, ref(counter)));
    }

    for (int i = 0; i < 4; i++) {
        workers[i].join();
    }

    std::cout << "Counter 최종 값 : " << counter << std::endl;
    }

CODE 13 -> atomic의 템플릿 인자로 원자적으로 만들고 싶은 타입을 전달
    -> 0으로 초기화 된 원자적인 변수를 정의 -> atomic 객체에서 제공하는 함수들을 통해, 여러가지 원자작인 연산들을 쉽게 수행

CODE 6 ~ 10 -> couter ++ ; 을 아무런 뮤텍스로 보호자지 않아도 정확히 40000으로 출력
    -> 어셈블리에서   lock add DWORD PTR [rdi], 1 을 나타난 것을 알 수 있음
    -> lock add 의 경우 rdi 에 위치한 메모리를 읽고 -1 더하고 다시 rdi에 위치한 메모리에 쓰기를 모두 해버림
        -> cpu는 원래 한 명령어에 하나만 할 수 있음 (쓰기 혹은 읽기)


    std::atomic<int> x;
    std::cout << "is lock free ? : " << boolalpha << x.is_lock_free() << std::endl;
    -> atomic 객체의 연산들이 원자적으로 구현 될 수 있는지 확인하는 함수
        -> is_lock_free()
        -> true 값
        -> lock free 의 lock 은 실제 어셈블리 명령 lock 과 다름 -> lock이 없다 라는 뜻,
            -> 즉, lock, unlock 없이도 해당 연산을 수행


* memory_order
    -> atomic 객체들의 경우 원천적 연산 시에 메모리에 접근할 때 접근 방식 지정

# memory_order_relexed
    -> 느슨한 조건, 메모리를 읽거나 쓸 경우, 주위의 다른 메모리 접근들과 순서가 바뀌어도 무방

    ex1)
    #include <atomic>
    #include <cstdio>
    #include <thread>
    #include <vector>
    using std::memory_order_relaxed;

    void t1(std::atomic<int>* a, std::atomic<int>* b) {
    b->store(1, memory_order_relaxed);      // b = 1 (쓰기)
    int x = a->load(memory_order_relaxed);  // x = a (읽기)

    printf("x : %d \n", x);
    }

    void t2(std::atomic<int>* a, std::atomic<int>* b) {
    a->store(1, memory_order_relaxed);      // a = 1 (쓰기)
    int y = b->load(memory_order_relaxed);  // y = b (읽기)

    printf("y : %d \n", y);
    }

    int main() {
        std::vector<std::thread> threads;

        std::atomic<int> a(0);
        std::atomic<int> b(0);

        threads.push_back(std::thread(t1, &a, &b));
        threads.push_back(std::thread(t2, &a, &b));

        for (int i = 0; i < 2; i++) {
            threads[i].join();
    }
    }

CODE 7 ~ 12
    8, 9 -> store과 load는 atomic 객체들에 대해 원자적으로 쓰기와 읽기를 지원해주는 함수.
        -> 어떠한 형태로 memory_order을 지정할 것인가 전달 할 수 있음.
        -> memory_order_relaxed 방식
        ->cpu가 순서를 재배치 하여 실행해도 무방
    -> x, y 값에 0이 들어감. -> 불가능
        -> 이론상 x,y에 0이 들어가기 위해서는 a, b는 0이여야 하고 즉, a=1, 이 실행 되지 않아야함
        -> memory_order_relaxed은 메모리 연산들 사이에서 어떠한 제약도 없다고 했기에 -> 메모리 연산은 cpu에서 재배치

        -> 둘 다 0?
            int x = a->load(memory_order_relaxed);  // x = a (읽기)
            b->store(1, memory_order_relaxed);      // b = 1 (쓰기)
            -> 가능

    -> 실제값은 x=1, y=0, 또는 x=0, y=1 이 나오면서 한쪽이 실행된 시점에서 다른 한쪽은 a,b=1 하나 실행됐었다면, 그 상태에서 1이 출력 x,y cpu 자동 재배치로 출력

    -> memory_order_relaxed 는 cpu 메모리 연산 순서에 자유를 줌 -> cpu에서 매우 빠른 속도로 실행
    -> relaxed 메모리 연산을 사용하면 예상치 못한 결과가 나옴.


# memory_order_acquire 과 memory_order_release
    -> memory_order_relaxed는 너무 많은 cpu에 자유를 부여하기에 사용 용도가 제한적
    
    ex1) producer - consumer
    #include <atomic>
    #include <iostream>
    #include <thread>
    #include <vector>
    using std::memory_order_relaxed;

    void producer(std::atomic<bool>* is_ready, int* data) {
    *data = 10;
    is_ready->store(true, memory_order_relaxed);
    }

    void consumer(std::atomic<bool>* is_ready, int* data) {
    // data 가 준비될 때 까지 기다린다.
    while (!is_ready->load(memory_order_relaxed)) {
    }

    std::cout << "Data : " << *data << std::endl;
    }

    int main() {
        std::vector<std::thread> threads;

        std::atomic<bool> is_ready(false);
        int data = 0;

        threads.push_back(std::thread(producer, &is_ready, &data));
        threads.push_back(std::thread(consumer, &is_ready, &data));

        for (int i = 0; i < 2; i++) {
            threads[i].join();
        }
    }

-> data : 10 출력, data : 0 도 가능한지? -> 가능

CODE 7~ 10 -> is_ready 에 쓰는 연산이 relaxed이기 때문에 위의 *data=10 과 순서가 바뀐다면?
    -> is_ready가 true 임에도 *data = 10 에서 실행이 끝나지 않음

CODE 12 ~ 18 -> 마찬가지로 is_ready가 true 라도 제대로된 data를 읽을 수 없음


    ex2)
    #include <atomic>
    #include <iostream>
    #include <thread>
    #include <vector>

    void producer(std::atomic<bool>* is_ready, int* data) {
    *data = 10;
    is_ready->store(true, std::memory_order_release);
    }

    void consumer(std::atomic<bool>* is_ready, int* data) {
    // data 가 준비될 때 까지 기다린다.
    while (!is_ready->load(std::memory_order_acquire)) {
    }

    std::cout << "Data : " << *data << std::endl;
    }

    int main() {
        std::vector<std::thread> threads;

        std::atomic<bool> is_ready(false);
        int data = 0;

        threads.push_back(std::thread(producer, &is_ready, &data));
        threads.push_back(std::thread(consumer, &is_ready, &data));

        for (int i = 0; i < 2; i++) {
            threads[i].join();
        }
    }

    ->data에 0이 들어갈 수 없음 - 불가능

CODE 8 -> memory_order_relaxed 는 해당 명령 이전의 모든 메모리 명령들이 해당 명령 이후로 재배치 되는 것을 금지
    -> 같은 변수에 memory_order_acquire 였다면 오는 메모리 명령들이 해당 쓰레드에 의해 관찰 될 수 있어야함.
        -> 즉, is_ready->store(true, std::memory_order_release);
        -> 밑에 *data = 10 이 올 수 없게 됨

    -> is_ready 가 true 가 된다면, memory_order_acquire 로 is_ready 를 읽는 쓰레드에서 data 의 값을 확인했을 때 10 임을 관찰

CODE 13 -> is_ready 를 memory_order_acquire 로 load 하고 있기에, is_ready 가 true 가 된다면, data 는 반드시 10
    -> memory_order_acquire -> release 와 반대로 해당 명령 뒤에 오는 모든 메모리 명령들이 해당 명령 위로 재배치


    -> release 와 acquire 를 통해서 동기화 (synchronize) 를 수행


# memory_order_acq_rel
    -> acquire, release 모두 수행 -> 읽기와 쓰기를 모두 수행하는 명령어 ex, fetch_add

# memory_order_seq_cst
    -> 메모리 명령의 순차적 일관성 (sequential consistency) 를 보장
    -> 순차적 일관성이란?, 메모리 명령 재배치도 없고, 모든 쓰레드에서 모든 시점에 동일한 값을 관찰할 수 있는, cpu가 작동하는 방식
    

    ex1)
    #include <atomic>
    #include <iostream>
    #include <thread>

    std::atomic<bool> x(false);
    std::atomic<bool> y(false);
    std::atomic<int> z(0);

    void write_x() { x.store(true, std::memory_order_release); }

    void write_y() { y.store(true, std::memory_order_release); }

    void read_x_then_y() {
    while (!x.load(std::memory_order_acquire)) {
    }
    if (y.load(std::memory_order_acquire)) {
        ++z;
    }
    }

    void read_y_then_x() {
    while (!y.load(std::memory_order_acquire)) {
    }
    if (x.load(std::memory_order_acquire)) {
        ++z;
    }
    }

    int main() {
        thread a(write_x);
        thread b(write_y);
        thread c(read_x_then_y);
        thread d(read_y_then_x);
        a.join();
        b.join();
        c.join();
        d.join();
        std::cout << "z : " << z << std::endl;
    }
-> write_x 와 read_x_then_y 사이의 release - acquire 동기화와, write_y 와 read_y_then_x 사이의 release - acquire 동기화가 이루어지고 있음
    -> read_x_then_y 와 read_y_then_x 쓰레드가 같은 순서로 x.store와 y.store 를 관찰하는 보장은 없음
        -> 즉, read_x_then_y 입장에서는 x.store 가 y.store 보다 먼 저 발생해도 되고, read_y_then_x 에서는 y.store 가 x.strore 보다 먼저 발생해도 됨.

    -> 하지만 이 경우 두 if 문 안의 load 가 false 가 되어서 z 가 0 이 됨.


    ex2) memory_order_seq_cst 사용

    #include <atomic>
    #include <iostream>
    #include <thread>
    using std::memory_order_seq_cst;
    using std::thread;

    std::atomic<bool> x(false);
    std::atomic<bool> y(false);
    std::atomic<int> z(0);

    void write_x() { x.store(true, memory_order_seq_cst); }

    void write_y() { y.store(true, memory_order_seq_cst); }

    void read_x_then_y() {
    while (!x.load(memory_order_seq_cst)) {
    }
    if (y.load(memory_order_seq_cst)) {
        ++z;
    }
    }

    void read_y_then_x() {
    while (!y.load(memory_order_seq_cst)) {
    }
    if (x.load(memory_order_seq_cst)) {
        ++z;
    }
    }

    int main() {
        thread a(write_x);
        thread b(write_y);
        thread c(read_x_then_y);
        thread d(read_y_then_x);
        a.join();
        b.join();
        c.join();
        d.join();
        std::cout << "z : " << z << std::endl;
    }
    -> memory_order_seq_cst 사용하게 되면, 해당 멸영을 사용하는 메모리 연산들 끼리 모든 쓰레드를 동일한 연산 순서로 관찰 보장
    -> z가 0이 되는 경우 x




cpu 명령 정리
쓰기 (store)
memory_order_relaxed, memory_order_release, memory_order_seq_cst

읽기 (load)
memory_order_relaxed, memory_order_consume, memory_order_acquire, memory_order_seq_cst

읽고 - 수정하고 - 쓰기 (read - modify - write)
memory_order_relaxed, memory_order_consume, memory_order_acquire,
memory_order_release, memory_order_acq_rel, memory_order_seq_cst