* Object detection, 객체 인식
    -> 이미지 또는 비디오에서 개체를 식별하고 찾는 것과 관련된 컴퓨터 비전 작업.
    -> 감지된 물체는 사람일 수도, 자동차나 건물, 동물 일수도 있다.

# You Only Look Once
    -> YOLO 는 최첨단 실시간 Object detection 시스템
    -> 물체 감지와 객체 인식에 대한 딥러닝 기반 접근 방식

    구조 - 
    -> 입력된 이미지를 일정 분할로 그리드한 다음, 신경망을 통과하여 바운딩 박스와 클래스 예측을 생성하여 최종 감지 출력을 결정
        1. OCR 과정 -> 사진, 스캔된 문서, 비디오 등에서 텍스트를 인식하고 추출하는데 사용되는 컴퓨터 알고리즘.(컴퓨터가 읽을 수 있는 데이터 형식으로 변환)
            1.1 전처리 : 이미지의 품질 개선, 노이즈 제거, 글자 인식률을 높임 -> 이미지 이진화, 블러 처리, 배경 제거 등의 작업이 포함
            1.2 문자 분할 : 이미지에서 문자 영역을 찾아내고 분리하는 과정 -> 텍스트 영역 검출, 라인 분할, 문자 분할 등이 이루어짐.
            1.3 문자 인식 : 분리된 문자 영역에서 실제 문자를 인식하는 과정 -> Image Classification (이미지 분류) 모델을 사용
            1.4 후처리 : 인식된 문자를 정체 후, 올바른 결과를 도출 -> 이 단계에서는 단어 검사, 문법 검사, 언어 모델을 사용하여 오류를 수정하고 최종 출력

    -> 실제 이미지 및 비디오에서 테스트하기 전에 먼저 전체 데이터 세트에 대해 여러 인스턴스를 학습


* YOLO 원리

# YOLO structure
 - 그리드에서 분할한 이미지를 신경망에 통과 -> Bbox 나 예측을 통한 최종 감지 출력
 - Bbox 를 계산하기 위해 IoU(Intersect over Union) 및 NMS(Non-maximum suppression) 의 주요 후처리 단계를 구현
    - IoU? -> Object detection 의 정확도를 측정하는데 이용되는 평가 지표
        1. ground-truth bounding boxes(testing set 에서 object 위치를 labeling 한 것)
        2. prediceted bounding boxes (model이 출력한 object 위치 예측값)

        -> 얼마나 정확히 객체 위치를 탐지했는지 확인하기 위한 IoU 계산
            -> IoU = Area of Overlap / Area of Union
            -> area of overlab 은 prediceted bounding box 와 ground-truth bounding box 가 겹치는 부분 (교집합?)
            -> area of Union prediceted bounding box 와 ground-truth bounding box 둘러싸는 영역 (합집합?)
        
        -> 사용 이유?
            -> detection에서는 분류 문제를 수행 할 때 prediceted class 를 쉽게 확인 할 수 없다.
            -> 현실 문제에서 predicted bounding box가 정확히 ground-truth bounding box와 일치하지 경우는 거의 없음
            -> 이 때문에 predicted bounding box가 ground-truth bounding box와 얼마나 일치하는지 측정하기 위한 평가 지표를 정의

    - NMS(최대 억제)? -> object detection 이 예측한 bounding box 중에서 정확한 bounding box 를 선택하도록 하는 기법
        -> 이미지에서 객체는 다양한 크기와 형태로 존재 -> 완벽하게 검출하기 위해 object detection 알고리즘은 여러 개의 bounding boxes를 생성
            -> 이때 하나의 bounding box 만을 선택해야 하는데 이때 적용하는 기법이 Non-max suppression

        -> Non-max suppression 알고리즘 작동 단계
            1. 하나의 클래스에 대한 bounding boxes 목록에서 가장 높은 점수를 갖고 있는 bounding box를 선택하고 목록에서 제거, -> final box 추가
            2. 선택된 bounding box 를 bounding boxes 목록에 있는 모든 bounding box 와 IoU를 계산하여 비교 -> IoU가 threshold 보다 높으면 bounding boxes 목록에서 제거
            3. bounding boxes 목록에 남아있는 bounding box에서 가장 높은 점수를 갖고 있는 것을 선택하고 목록에서 제거 -> final box 에 추가
            4. 다시 선택된 bounding box를 목록에 있는 box들과 IoU를 비교 -> threshold보다 높으면 목록에서 제거
            5. bounding boxes에 아무것도 남아 있지 않을 때 까지 반복
            6. 각각의 클래스에 대해 위 과정을 반복

 - 먼저 IoU는 모델이 예측한 bounding box와 실제 개체의 그것이 얼마나 잘 일치하는지 확인, 두 결과의 겹침이 IoU 제공
 - 개체 알고리즘은 종종, 특정 개체를 과도하게 식별하는 문제 -> 관심 개념을 로컬라이즈하는 단계에서, 실제 위치 근처에서 여러 개의 감지 그룹이 생성되는 현상은 불완전한 감지 알고리즘의 고칠적인 현상
 - NMS 는 이를 방지하기 위해 컴퓨터 비전의 여러 영역에서 사용
    -> 사용하면 얼굴이 속한 모든 후보 중에 최적의 셀을 식별, 동일한 객체에 대한 상자 중 가장  높은 확률을 가진 상자를 선택
    

# How To
    -> IoU 와 NMS 모두를 활용하여 이미지의 다양한 개체를 빠르게 예측 -> 모델은 훈련을 받는 과정에서 전체 이미지를 확인, 클래스에 대한 컨텍스트 정보나 클래스가 보는 이미지의 모양을 암시적으로 인코딩
        1. 입력한 이미지를 확인
        2. 사진을 N X N 의 그리드로 나눔 -> 각 그리드마다 이미지 분류 및 지역화 작업이 시작, 객체가 어디에 있는지 확인, 식별해야 하는 객체에 Bbox를 그림
        3. YOLO 알고리즘은 bounding box 와 개체의 클래스 확률을 통해 객체를 인식하고 예측
        4. 

* YOLO vs R-CNN
    -> YOLO - 주어진 이미지를 한 번의 스캔으로 객체의 위치와 경계선을 계산
    -> R-CNN - 이미지 안에 객체가 있을 만한 부분을 미리 예측하고, 컨볼루션 넷을 이용해 특징을 추출하는 과정을 거침

    -- > yolo 이 단계에서 간략화하여 실시간 처리를 가능하게 했음.


버전별 yolo
YOLO v1 (2016): 실시간 객체 검출을 위한 딥러닝 기반의 네트워크
YOLO v2 (2017): v1에서 성능 개선 및 속도 향상
YOLO v3 (2018): 네트워크 구조와 학습 방법을 개선하여 Object Detection 정확도와 속도 개선
YOLO v4 (2020. 04): SPP와 AN 기술을 적용하여 Object Detection 정확도와 속도 개선
YOLO v5 (2020. 06): 전작보다 정확도 10% 이상 향상, 모델 크기 축소
YOLO v6 (2022. 07): 훈련 과정의 최적화, Trainable bag-of-freebies 제안
YOLO v7 (2022. 09) 알고리즘의 효율성 향상, 시스템 탑재를 위한 Quantization과 Distillation 방식 도입
YOLO v8 (2023. 01): 새로운 저장소를 출시하여 객체 감지, 인스턴스 세분화 및 이미지 분류 모델 Train을 위한 통합 프레임 워크로 구축

